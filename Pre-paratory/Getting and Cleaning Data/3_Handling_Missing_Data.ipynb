{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Data\n",
    "\n",
    "In this section, we will study ways to identify and treat missing data. We will:\n",
    "- Identify missing data in dataframes\n",
    "- Treat (delete or impute) missing values\n",
    "\n",
    "There are various reasons for missing data, such as, human-errors during data-entry, non availability at the end of the user (e.g. DOB of certain people), etc. Most often, the reasons are simply unknown.\n",
    "\n",
    "In python, missing data is represented using either of the two objects ```NaN``` (Not a Number) or ```NULL```. We'll not get into the differences between them and how Python stores them internally etc. We'll focus on studying ways to identify and treat missing values in Pandas dataframes.\n",
    "\n",
    "There are four main methods to identify and treat missing data:\n",
    "- ```isnull()```: Indicates presence of missing values, returns a boolean\n",
    "- ```notnull()```: Opposite of ```isnull()```, returns a boolean\n",
    "- ```dropna()```: Drops the missing values from a data frame and returns the rest\n",
    "- ```fillna()```: Fills (or imputes) the missing values by a specified value\n",
    "\n",
    "\n",
    "For this exercise, we will use the **Melbourne house pricing dataset**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>68 Studley St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS</td>\n",
       "      <td>Jellis</td>\n",
       "      <td>03-09-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8014</td>\n",
       "      <td>144.9958</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>85 Turner St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>03-12-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>04-02-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>18/659 Victoria St</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VB</td>\n",
       "      <td>Rounds</td>\n",
       "      <td>04-02-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8114</td>\n",
       "      <td>145.0116</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>5 Charles St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>04-03-2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Suburb             Address  Rooms Type      Price Method SellerG  \\\n",
       "0  Abbotsford       68 Studley St      2    h        NaN     SS  Jellis   \n",
       "1  Abbotsford        85 Turner St      2    h  1480000.0      S  Biggin   \n",
       "2  Abbotsford     25 Bloomburg St      2    h  1035000.0      S  Biggin   \n",
       "3  Abbotsford  18/659 Victoria St      3    u        NaN     VB  Rounds   \n",
       "4  Abbotsford        5 Charles St      3    h  1465000.0     SP  Biggin   \n",
       "\n",
       "         Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n",
       "0  03-09-2016       2.5    3067.0  ...       1.0  1.0     126.0           NaN   \n",
       "1  03-12-2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n",
       "2  04-02-2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n",
       "3  04-02-2016       2.5    3067.0  ...       2.0  1.0       0.0           NaN   \n",
       "4  04-03-2017       2.5    3067.0  ...       2.0  0.0     134.0         150.0   \n",
       "\n",
       "   YearBuilt  CouncilArea Lattitude  Longtitude             Regionname  \\\n",
       "0        NaN        Yarra  -37.8014    144.9958  Northern Metropolitan   \n",
       "1        NaN        Yarra  -37.7996    144.9984  Northern Metropolitan   \n",
       "2     1900.0        Yarra  -37.8079    144.9934  Northern Metropolitan   \n",
       "3        NaN        Yarra  -37.8114    145.0116  Northern Metropolitan   \n",
       "4     1900.0        Yarra  -37.8093    144.9944  Northern Metropolitan   \n",
       "\n",
       "  Propertycount  \n",
       "0        4019.0  \n",
       "1        4019.0  \n",
       "2        4019.0  \n",
       "3        4019.0  \n",
       "4        4019.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"melbourne.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first few rows contain missing values, represented as NaN.\n",
    "\n",
    "Let's quickly look at the structure of the data frame, types of columns, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23547, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23547 entries, 0 to 23546\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Suburb         23547 non-null  object \n",
      " 1   Address        23547 non-null  object \n",
      " 2   Rooms          23547 non-null  int64  \n",
      " 3   Type           23547 non-null  object \n",
      " 4   Price          18396 non-null  float64\n",
      " 5   Method         23547 non-null  object \n",
      " 6   SellerG        23547 non-null  object \n",
      " 7   Date           23547 non-null  object \n",
      " 8   Distance       23546 non-null  float64\n",
      " 9   Postcode       23546 non-null  float64\n",
      " 10  Bedroom2       19066 non-null  float64\n",
      " 11  Bathroom       19063 non-null  float64\n",
      " 12  Car            18921 non-null  float64\n",
      " 13  Landsize       17410 non-null  float64\n",
      " 14  BuildingArea   10018 non-null  float64\n",
      " 15  YearBuilt      11540 non-null  float64\n",
      " 16  CouncilArea    15656 non-null  object \n",
      " 17  Lattitude      19243 non-null  float64\n",
      " 18  Longtitude     19243 non-null  float64\n",
      " 19  Regionname     23546 non-null  object \n",
      " 20  Propertycount  23546 non-null  float64\n",
      "dtypes: float64(12), int64(1), object(8)\n",
      "memory usage: 3.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# approx 23k rows, 21 columns\n",
    "print(df.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Missing Values\n",
    "\n",
    "The methods ```isnull()``` and ```notnull()``` are the most common ways of identifying missing values. \n",
    "\n",
    "While handling missing data, you first need to identify the rows and columns containing missing values, count the number of missing values, and then decide how you want to treat them.\n",
    "\n",
    "It is important that **you treat missing values in each column separately**, rather than implementing a single solution (e.g. replacing NaNs by the mean of a column) for all columns.\n",
    "\n",
    "```isnull()``` returns a boolean (True/False) which can then be used to find the rows or columns containing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23542</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23543</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23544</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23545</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23546</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23547 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Suburb  Address  Rooms   Type  Price  Method  SellerG   Date  Distance  \\\n",
       "0       False    False  False  False   True   False    False  False     False   \n",
       "1       False    False  False  False  False   False    False  False     False   \n",
       "2       False    False  False  False  False   False    False  False     False   \n",
       "3       False    False  False  False   True   False    False  False     False   \n",
       "4       False    False  False  False  False   False    False  False     False   \n",
       "...       ...      ...    ...    ...    ...     ...      ...    ...       ...   \n",
       "23542   False    False  False  False   True   False    False  False     False   \n",
       "23543   False    False  False  False   True   False    False  False     False   \n",
       "23544   False    False  False  False  False   False    False  False     False   \n",
       "23545   False    False  False  False  False   False    False  False     False   \n",
       "23546   False    False  False  False  False   False    False  False     False   \n",
       "\n",
       "       Postcode  ...  Bathroom    Car  Landsize  BuildingArea  YearBuilt  \\\n",
       "0         False  ...     False  False     False          True       True   \n",
       "1         False  ...     False  False     False          True       True   \n",
       "2         False  ...     False  False     False         False      False   \n",
       "3         False  ...     False  False     False          True       True   \n",
       "4         False  ...     False  False     False         False      False   \n",
       "...         ...  ...       ...    ...       ...           ...        ...   \n",
       "23542     False  ...     False  False     False         False      False   \n",
       "23543     False  ...      True   True      True          True       True   \n",
       "23544     False  ...     False  False      True          True       True   \n",
       "23545     False  ...     False  False     False         False      False   \n",
       "23546     False  ...     False  False      True         False      False   \n",
       "\n",
       "       CouncilArea  Lattitude  Longtitude  Regionname  Propertycount  \n",
       "0            False      False       False       False          False  \n",
       "1            False      False       False       False          False  \n",
       "2            False      False       False       False          False  \n",
       "3            False      False       False       False          False  \n",
       "4            False      False       False       False          False  \n",
       "...            ...        ...         ...         ...            ...  \n",
       "23542         True      False       False       False          False  \n",
       "23543         True      False       False       False          False  \n",
       "23544         True      False       False       False          False  \n",
       "23545         True      False       False       False          False  \n",
       "23546         True      False       False       False          False  \n",
       "\n",
       "[23547 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isnull()\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Identifying Missing Values in Columns\n",
    "Let's first compute the total number of missing values in the data frame. You can calculate the number of missing values in each column by ```df.isnull().sum()``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb               0\n",
       "Address              0\n",
       "Rooms                0\n",
       "Type                 0\n",
       "Price             5151\n",
       "Method               0\n",
       "SellerG              0\n",
       "Date                 0\n",
       "Distance             1\n",
       "Postcode             1\n",
       "Bedroom2          4481\n",
       "Bathroom          4484\n",
       "Car               4626\n",
       "Landsize          6137\n",
       "BuildingArea     13529\n",
       "YearBuilt        12007\n",
       "CouncilArea       7891\n",
       "Lattitude         4304\n",
       "Longtitude        4304\n",
       "Regionname           1\n",
       "Propertycount        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summing up the missing values (column-wise)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some columns have extremely **large number of missing values**, such as Price, Bedroom2, Bathroom, BuildingArea, YearBuilt etc. In such cases, one should be careful in handling missing values, since if you replace them by arbitrary numbers such as mean, median etc., the entire further analysis may throw unrealistic or unexpected results.\n",
    "\n",
    "The functions ```any()``` and ```all()``` are quite useful to identify rows and columns having missing values:\n",
    "- ```any()``` returns ```True``` when at least one value satisfies a condition (equivalent to logical ```or```)\n",
    "- ```all()``` returns ```True``` when all the values satisfy a condition (equivalent to logical ```and```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb           False\n",
       "Address          False\n",
       "Rooms            False\n",
       "Type             False\n",
       "Price             True\n",
       "Method           False\n",
       "SellerG          False\n",
       "Date             False\n",
       "Distance          True\n",
       "Postcode          True\n",
       "Bedroom2          True\n",
       "Bathroom          True\n",
       "Car               True\n",
       "Landsize          True\n",
       "BuildingArea      True\n",
       "YearBuilt         True\n",
       "CouncilArea       True\n",
       "Lattitude         True\n",
       "Longtitude        True\n",
       "Regionname        True\n",
       "Propertycount     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns having at least one missing value\n",
    "df.isnull().any()\n",
    "\n",
    "# above is equivalent to axis=0 (by default, any() operates on columns)\n",
    "df.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have identified columns having missing values and have computed the number of missing values in each. Let's do the same for rows.\n",
    "\n",
    "### Identifying  Missing Values in Rows\n",
    "\n",
    "The methods ```any()``` and ```all()``` can be used to identify rows having **at least one** and **all** missing values respectively. To specify that the operation should be done on rows, you need to use ```axis=1``` as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1         True\n",
       "2        False\n",
       "3         True\n",
       "4        False\n",
       "         ...  \n",
       "23542     True\n",
       "23543     True\n",
       "23544     True\n",
       "23545     True\n",
       "23546     True\n",
       "Length: 23547, dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows having at least one missing value\n",
    "df.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "23542    False\n",
       "23543    False\n",
       "23544    False\n",
       "23545    False\n",
       "23546    False\n",
       "Length: 23547, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows having all missing values\n",
    "df.isnull().all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum it up to check how many rows have all missing values\n",
    "df.isnull().all(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, there are no rows having all missing values (we'd remove them if there were any). \n",
    "\n",
    "Often, you may also want to remove the rows having more than a certain threshold number of missing values. To do that, you need to count the number of missing values in each row using ```sum()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3\n",
       "1        2\n",
       "2        0\n",
       "3        3\n",
       "4        0\n",
       "        ..\n",
       "23542    2\n",
       "23543    8\n",
       "23544    4\n",
       "23545    1\n",
       "23546    2\n",
       "Length: 23547, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of misisng values in each row\n",
    "df.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now identified:\n",
    "- The number of missing values in columns\n",
    "- The number of missing values in rows\n",
    "\n",
    "Let's now move ahead and treat the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating Missing Values\n",
    "\n",
    "There are broadly two ways to treat missing values:\n",
    "1. Delete: Delete the missing values \n",
    "2. Impute: \n",
    "    - Imputing by a simple statistic: Replace the missing values by another value, commonly the mean, median, mode etc. \n",
    "    - Predictive techniques: Use statistical models such as k-NN, SVM etc. to predict and impute missing values\n",
    "   \n",
    "\n",
    "In general, imputation makes assumptions about the missing values and replaces missing values by arbitrary numbers such as mean, median etc. It should be used only when you are reasonably confident about the assumptions.\n",
    "\n",
    "Otherwise, deletion is often safer and recommended. You may lose some data, but will not make any unreasonable assumptions.\n",
    "\n",
    "**Caution**: Always have a backup of the original data if you're deleting missing values.  \n",
    "\n",
    "<hr>\n",
    "**Additional Stuff for Nerds**\n",
    "\n",
    "How you treat missing values should ideally depend upon an understnading of why missing values occur. The reasons are classified into categories such as *missing completely at random, missing at random, misisngness that depends on the missing value itself etc.* \n",
    " \n",
    " \n",
    "We'll not discuss *why missing values occur*, though you can read this article if interested: http://www.stat.columbia.edu/~gelman/arm/missing.pdf\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating Missing Values in Columns\n",
    "\n",
    "Let's now treat missing values in columns. Let's look at the number of NaNs in each column again, this time as the *percentage of missing values in each column*. Notice that we calculate the number of rows as ```len(df.index)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb            0.00\n",
       "Address           0.00\n",
       "Rooms             0.00\n",
       "Type              0.00\n",
       "Price            21.88\n",
       "Method            0.00\n",
       "SellerG           0.00\n",
       "Date              0.00\n",
       "Distance          0.00\n",
       "Postcode          0.00\n",
       "Bedroom2         19.03\n",
       "Bathroom         19.04\n",
       "Car              19.65\n",
       "Landsize         26.06\n",
       "BuildingArea     57.46\n",
       "YearBuilt        50.99\n",
       "CouncilArea      33.51\n",
       "Lattitude        18.28\n",
       "Longtitude       18.28\n",
       "Regionname        0.00\n",
       "Propertycount     0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summing up the missing values (column-wise)\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are columns having almost 22%, 19%, 26%, 57% etc. missing values. When dealing with columns, you have two simple choices - either **delete or retain the column.** If you retain the column, you'll have to treat (i.e. delete or impute) the rows having missing values.\n",
    "\n",
    "If you delete the missing rows, you lose data. If you impute, you introduce bias.\n",
    "\n",
    "Apart from the number of missing values, the decision to delete or retain a variable depends on various other factors, such as:\n",
    "- the analysis task at hand\n",
    "- the usefulness of the variable (based on your understanding of the problem)\n",
    "- the total size of available data (if you have enough, you can afford to throw away some of it)\n",
    "- etc.\n",
    "\n",
    "For e.g. let's say that we want to build a (linear regression) model to predict the house prices in Melbourne. Now, even though the variable ```Price``` has about 22% missing values, you cannot drop the variable, since that is what you want to predict. \n",
    "\n",
    "Similarly, you would expect some other variables such as ```Bedroom2```, ```Bathroom```, ```Landsize``` etc. to be important predictors of ```Price```, and thus cannot remove those columns.\n",
    "\n",
    "There are others such as ```BuildingArea```, which although seem important, have more than 50% missing values. It is impossible to either delete or impute the rows corresponding to such large number of missing values without losing a lot of data or introducing heavy bias. \n",
    "\n",
    "\n",
    "\n",
    "Thus, for this exercise, let's remove the columns having more than 30% missing values, i.e. ```BuildingArea```, ```YearBuilt```, ```CouncilArea```.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb            0.00\n",
       "Address           0.00\n",
       "Rooms             0.00\n",
       "Type              0.00\n",
       "Price            21.88\n",
       "Method            0.00\n",
       "SellerG           0.00\n",
       "Date              0.00\n",
       "Distance          0.00\n",
       "Postcode          0.00\n",
       "Bedroom2         19.03\n",
       "Bathroom         19.04\n",
       "Car              19.65\n",
       "Landsize         26.06\n",
       "Lattitude        18.28\n",
       "Longtitude       18.28\n",
       "Regionname        0.00\n",
       "Propertycount     0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the three columns\n",
    "df = df.drop('BuildingArea', axis=1)\n",
    "df = df.drop('YearBuilt', axis=1)\n",
    "df = df.drop('CouncilArea', axis=1)\n",
    "\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have columns having maximum 26% missing values (```Landsize```). Next, we need to treat the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating Missing Values in Rows\n",
    "\n",
    "Now, we need to either delete or impute the missing values. First, let's see if there are any rows having a significant number of missing values. If so, we can drop those rows, and then take a decision to delete or impute the rest.\n",
    "\n",
    "After dropping three columns, we now have 18 columns to work with. Just to inspect rows with missing values, let's have a look at the rows having more than 5 missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>217 Langridge St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Jellis</td>\n",
       "      <td>08-10-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>18a Mollison St</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>745000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Jellis</td>\n",
       "      <td>08-10-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>403/609 Victoria St</td>\n",
       "      <td>2</td>\n",
       "      <td>u</td>\n",
       "      <td>542000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Dingle</td>\n",
       "      <td>08-10-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25/84 Trenerry Cr</td>\n",
       "      <td>2</td>\n",
       "      <td>u</td>\n",
       "      <td>760000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>10-12-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>106/119 Turner St</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>481000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Purplebricks</td>\n",
       "      <td>10-12-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23495</th>\n",
       "      <td>Templestowe Lower</td>\n",
       "      <td>1/207 Manningham Rd</td>\n",
       "      <td>2</td>\n",
       "      <td>u</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Barry</td>\n",
       "      <td>26-08-2017</td>\n",
       "      <td>12.4</td>\n",
       "      <td>3107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Metropolitan</td>\n",
       "      <td>5420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23499</th>\n",
       "      <td>Thornbury</td>\n",
       "      <td>1/128 Dundas St</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>770000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>McGrath</td>\n",
       "      <td>26-08-2017</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23502</th>\n",
       "      <td>Thornbury</td>\n",
       "      <td>111 Pender St</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>858000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Jellis</td>\n",
       "      <td>26-08-2017</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23508</th>\n",
       "      <td>Toorak</td>\n",
       "      <td>21/1059 Malvern Rd</td>\n",
       "      <td>2</td>\n",
       "      <td>u</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>VB</td>\n",
       "      <td>Beller</td>\n",
       "      <td>26-08-2017</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>7217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23531</th>\n",
       "      <td>Werribee</td>\n",
       "      <td>91 Latham St</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>540000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Triwest</td>\n",
       "      <td>26-08-2017</td>\n",
       "      <td>14.7</td>\n",
       "      <td>3030.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>16166.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4278 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Suburb              Address  Rooms Type      Price Method  \\\n",
       "15            Abbotsford     217 Langridge St      3    h  1000000.0      S   \n",
       "16            Abbotsford      18a Mollison St      2    t   745000.0      S   \n",
       "19            Abbotsford  403/609 Victoria St      2    u   542000.0      S   \n",
       "21            Abbotsford    25/84 Trenerry Cr      2    u   760000.0     SP   \n",
       "22            Abbotsford    106/119 Turner St      1    u   481000.0     SP   \n",
       "...                  ...                  ...    ...  ...        ...    ...   \n",
       "23495  Templestowe Lower  1/207 Manningham Rd      2    u   550000.0     PI   \n",
       "23499          Thornbury      1/128 Dundas St      2    t   770000.0     PI   \n",
       "23502          Thornbury        111 Pender St      2    t   858000.0      S   \n",
       "23508             Toorak   21/1059 Malvern Rd      2    u   720000.0     VB   \n",
       "23531           Werribee         91 Latham St      4    h   540000.0     PI   \n",
       "\n",
       "            SellerG        Date  Distance  Postcode  Bedroom2  Bathroom  Car  \\\n",
       "15           Jellis  08-10-2016       2.5    3067.0       NaN       NaN  NaN   \n",
       "16           Jellis  08-10-2016       2.5    3067.0       NaN       NaN  NaN   \n",
       "19           Dingle  08-10-2016       2.5    3067.0       NaN       NaN  NaN   \n",
       "21           Biggin  10-12-2016       2.5    3067.0       NaN       NaN  NaN   \n",
       "22     Purplebricks  10-12-2016       2.5    3067.0       NaN       NaN  NaN   \n",
       "...             ...         ...       ...       ...       ...       ...  ...   \n",
       "23495         Barry  26-08-2017      12.4    3107.0       NaN       NaN  NaN   \n",
       "23499       McGrath  26-08-2017       7.0    3071.0       NaN       NaN  NaN   \n",
       "23502        Jellis  26-08-2017       7.0    3071.0       NaN       NaN  NaN   \n",
       "23508        Beller  26-08-2017       4.1    3142.0       NaN       NaN  NaN   \n",
       "23531       Triwest  26-08-2017      14.7    3030.0       NaN       NaN  NaN   \n",
       "\n",
       "       Landsize  Lattitude  Longtitude             Regionname  Propertycount  \n",
       "15          NaN        NaN         NaN  Northern Metropolitan         4019.0  \n",
       "16          NaN        NaN         NaN  Northern Metropolitan         4019.0  \n",
       "19          NaN        NaN         NaN  Northern Metropolitan         4019.0  \n",
       "21          NaN        NaN         NaN  Northern Metropolitan         4019.0  \n",
       "22          NaN        NaN         NaN  Northern Metropolitan         4019.0  \n",
       "...         ...        ...         ...                    ...            ...  \n",
       "23495       NaN        NaN         NaN   Eastern Metropolitan         5420.0  \n",
       "23499       NaN        NaN         NaN  Northern Metropolitan         8870.0  \n",
       "23502       NaN        NaN         NaN  Northern Metropolitan         8870.0  \n",
       "23508       NaN        NaN         NaN  Southern Metropolitan         7217.0  \n",
       "23531       NaN        NaN         NaN   Western Metropolitan        16166.0  \n",
       "\n",
       "[4278 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().sum(axis=1) > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice an interesting pattern - many rows have multiple columns missing. Since each row represents a house, it indicates that there are houses (observations) whose majority data has either not been collected or is unavailable. Such observations are anyway unlikely to contribute to prediction of prices. \n",
    "\n",
    "Thus we can remove the rows with (say) more than 5 missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4278"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of rows having > 5 missing values\n",
    "# use len(df.index)\n",
    "len(df[df.isnull().sum(axis=1) > 5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.16791948018856"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4278 rows have more than 5 missing values\n",
    "# calculate the percentage\n",
    "100*(len(df[df.isnull().sum(axis=1) > 5].index) / len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, about 18% rows have more than 5 missing values. Let's remove these rows and count the number of missing values remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb            0.00\n",
       "Address           0.00\n",
       "Rooms             0.00\n",
       "Type              0.00\n",
       "Price            21.71\n",
       "Method            0.00\n",
       "SellerG           0.00\n",
       "Date              0.00\n",
       "Distance          0.00\n",
       "Postcode          0.00\n",
       "Bedroom2          1.05\n",
       "Bathroom          1.07\n",
       "Car               1.81\n",
       "Landsize          9.65\n",
       "Lattitude         0.13\n",
       "Longtitude        0.13\n",
       "Regionname        0.00\n",
       "Propertycount     0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retaining the rows having <= 5 NaNs\n",
    "df = df[df.isnull().sum(axis=1) <= 5]\n",
    "\n",
    "# look at the summary again\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that now, we have removed most of the rows where multiple columns (```Bedroom2```, ```Bathroom```, ```Landsize```) were missing. \n",
    "\n",
    "Now, we still have about 21% missing values in the column ```Price``` and 9% in ```Landsize```. Since ```Price``` still contains a lot of missing data (and imputing 21% values of a variable you want to predict will introduce heavy bias), its a bad idea to impute those values. \n",
    "\n",
    "Thus, let's remove the missing rows in ```Price``` as well. Notice that you can use ```np.isnan(df['column'])``` to filter out the corresonding rows, and use a ```~``` to discard the values satisfying the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb           0.00\n",
       "Address          0.00\n",
       "Rooms            0.00\n",
       "Type             0.00\n",
       "Price            0.00\n",
       "Method           0.00\n",
       "SellerG          0.00\n",
       "Date             0.00\n",
       "Distance         0.00\n",
       "Postcode         0.00\n",
       "Bedroom2         1.05\n",
       "Bathroom         1.07\n",
       "Car              1.76\n",
       "Landsize         9.83\n",
       "Lattitude        0.15\n",
       "Longtitude       0.15\n",
       "Regionname       0.00\n",
       "Propertycount    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing NaN Price rows\n",
    "df = df[~np.isnan(df['Price'])]\n",
    "\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you have ```Landsize``` as the only variable having a significant number of missing values. Let's give this variable a chance and consider imputing the NaNs. \n",
    "\n",
    "The decision (whether and how to impute) will depend upon the distribution of the variable. For e.g., if the variable is such that all the observations lie in a short range (say between 800 sq. ft to 820 sq.ft), you can take a call to impute the missing values by something like the mean or median ```Landsize```. \n",
    "\n",
    "Let's look at the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     13603.000000\n",
       "mean        558.116371\n",
       "std        3987.326586\n",
       "min           0.000000\n",
       "25%         176.500000\n",
       "50%         440.000000\n",
       "75%         651.000000\n",
       "max      433014.000000\n",
       "Name: Landsize, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Landsize'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the minimum is 0, max is 433014, the mean is 558 and median (50%) is 440. There's a significant variation in the 25th and the 75th percentile as well (176 to 651). \n",
    "\n",
    "Thus, imputing this with mean/median seems quite biased, and so we should remove the NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb           0.00\n",
       "Address          0.00\n",
       "Rooms            0.00\n",
       "Type             0.00\n",
       "Price            0.00\n",
       "Method           0.00\n",
       "SellerG          0.00\n",
       "Date             0.00\n",
       "Distance         0.00\n",
       "Postcode         0.00\n",
       "Bedroom2         0.00\n",
       "Bathroom         0.01\n",
       "Car              0.46\n",
       "Landsize         0.00\n",
       "Lattitude        0.16\n",
       "Longtitude       0.16\n",
       "Regionname       0.00\n",
       "Propertycount    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing NaNs in Landsize\n",
    "df = df[~np.isnan(df['Landsize'])]\n",
    "\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reduced the NaNs significantly now. Only the variables ```Bathroom```, ```Car```, ```Lattitude``` and ```Longitude``` have a small number of missing values (most likely, the same rows will have ```Lattitude``` and ```Longitude``` missing).\n",
    "\n",
    "Let's first look at ```Lattitude``` and ```Longitude```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>Burwood</td>\n",
       "      <td>23 Monica St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>990000.0</td>\n",
       "      <td>VB</td>\n",
       "      <td>Fletchers</td>\n",
       "      <td>17-09-2016</td>\n",
       "      <td>11.7</td>\n",
       "      <td>3125.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>5678.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>Clifton Hill</td>\n",
       "      <td>3/268 Alexandra Pde E</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>363000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>hockingstuart</td>\n",
       "      <td>27-06-2016</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3068.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>2954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>Footscray</td>\n",
       "      <td>483 Barkly St</td>\n",
       "      <td>3</td>\n",
       "      <td>t</td>\n",
       "      <td>781000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Jas</td>\n",
       "      <td>27-11-2016</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>7570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>Hampton East</td>\n",
       "      <td>7 Seafoam St</td>\n",
       "      <td>4</td>\n",
       "      <td>t</td>\n",
       "      <td>1185000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>RT</td>\n",
       "      <td>28-05-2016</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3188.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>2356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10745</th>\n",
       "      <td>Williamstown North</td>\n",
       "      <td>4/9 Adeline St</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>355000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Sweeney</td>\n",
       "      <td>27-11-2016</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>802.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13223</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>1913/228 Abeckett St</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>1175000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Icon</td>\n",
       "      <td>29-04-2017</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>17496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14008</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>9 Richards Ct</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>hockingstuart</td>\n",
       "      <td>20-05-2017</td>\n",
       "      <td>10.9</td>\n",
       "      <td>3012.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14132</th>\n",
       "      <td>North Melbourne</td>\n",
       "      <td>13/201 Abbotsford St</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>755000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>29-04-2017</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>6821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14139</th>\n",
       "      <td>Oakleigh South</td>\n",
       "      <td>4 Druitt St</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>1205500.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Woodards</td>\n",
       "      <td>22-04-2017</td>\n",
       "      <td>14.7</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South-Eastern Metropolitan</td>\n",
       "      <td>3692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14142</th>\n",
       "      <td>Oakleigh South</td>\n",
       "      <td>298 Warrigal Rd</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>799999.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Woodards</td>\n",
       "      <td>29-04-2017</td>\n",
       "      <td>14.7</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South-Eastern Metropolitan</td>\n",
       "      <td>3692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14143</th>\n",
       "      <td>Oakleigh South</td>\n",
       "      <td>11 Yarra Ct</td>\n",
       "      <td>5</td>\n",
       "      <td>h</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Buxton</td>\n",
       "      <td>29-04-2017</td>\n",
       "      <td>14.7</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South-Eastern Metropolitan</td>\n",
       "      <td>3692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14976</th>\n",
       "      <td>Essendon</td>\n",
       "      <td>9 Washington St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1520000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Brad</td>\n",
       "      <td>03-06-2017</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3040.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>9264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15278</th>\n",
       "      <td>Seddon</td>\n",
       "      <td>60 Station Rd</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Sweeney</td>\n",
       "      <td>03-06-2017</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>2417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15561</th>\n",
       "      <td>Croydon</td>\n",
       "      <td>3 Silvergrass Ct</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>McGrath</td>\n",
       "      <td>17-06-2017</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3136.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Metropolitan</td>\n",
       "      <td>11925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16358</th>\n",
       "      <td>Kensington</td>\n",
       "      <td>201/102 Rankins Rd</td>\n",
       "      <td>2</td>\n",
       "      <td>u</td>\n",
       "      <td>876000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Rendina</td>\n",
       "      <td>24-06-2017</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3031.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>5263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16564</th>\n",
       "      <td>Strathmore</td>\n",
       "      <td>48 Lebanon St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>950000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Considine</td>\n",
       "      <td>24-06-2017</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3041.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17616</th>\n",
       "      <td>Kensington</td>\n",
       "      <td>109/102 Rankins Rd</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>410000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Rendina</td>\n",
       "      <td>08-07-2017</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3031.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>5263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17620</th>\n",
       "      <td>Keysborough</td>\n",
       "      <td>19 Denmark Rd</td>\n",
       "      <td>5</td>\n",
       "      <td>h</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>VicHomes</td>\n",
       "      <td>08-07-2017</td>\n",
       "      <td>25.2</td>\n",
       "      <td>3173.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South-Eastern Metropolitan</td>\n",
       "      <td>8459.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18141</th>\n",
       "      <td>Lalor</td>\n",
       "      <td>83 Rotino Cr</td>\n",
       "      <td>3</td>\n",
       "      <td>t</td>\n",
       "      <td>463000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>HAR</td>\n",
       "      <td>12-08-2017</td>\n",
       "      <td>16.3</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>8279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18614</th>\n",
       "      <td>Mickleham</td>\n",
       "      <td>17 Primavera Dr</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>610000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Ray</td>\n",
       "      <td>15-07-2017</td>\n",
       "      <td>20.6</td>\n",
       "      <td>3064.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>1158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18793</th>\n",
       "      <td>Wollert</td>\n",
       "      <td>13 Strathalbyn Ch</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>631000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>hockingstuart</td>\n",
       "      <td>15-07-2017</td>\n",
       "      <td>25.5</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>2940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18995</th>\n",
       "      <td>Greenvale</td>\n",
       "      <td>40 Frontier Av</td>\n",
       "      <td>3</td>\n",
       "      <td>t</td>\n",
       "      <td>470000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Barry</td>\n",
       "      <td>22-07-2017</td>\n",
       "      <td>20.4</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4864.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Suburb                Address  Rooms Type      Price  \\\n",
       "2572              Burwood           23 Monica St      3    h   990000.0   \n",
       "3257         Clifton Hill  3/268 Alexandra Pde E      1    u   363000.0   \n",
       "4485            Footscray          483 Barkly St      3    t   781000.0   \n",
       "5170         Hampton East           7 Seafoam St      4    t  1185000.0   \n",
       "10745  Williamstown North         4/9 Adeline St      1    u   355000.0   \n",
       "13223           Melbourne   1913/228 Abeckett St      3    u  1175000.0   \n",
       "14008            Brooklyn          9 Richards Ct      3    h   750000.0   \n",
       "14132     North Melbourne   13/201 Abbotsford St      2    t   755000.0   \n",
       "14139      Oakleigh South            4 Druitt St      4    h  1205500.0   \n",
       "14142      Oakleigh South        298 Warrigal Rd      3    h   799999.0   \n",
       "14143      Oakleigh South            11 Yarra Ct      5    h  1200000.0   \n",
       "14976            Essendon        9 Washington St      3    h  1520000.0   \n",
       "15278              Seddon          60 Station Rd      4    h  1500000.0   \n",
       "15561             Croydon       3 Silvergrass Ct      3    h   630000.0   \n",
       "16358          Kensington     201/102 Rankins Rd      2    u   876000.0   \n",
       "16564          Strathmore          48 Lebanon St      3    h   950000.0   \n",
       "17616          Kensington     109/102 Rankins Rd      1    u   410000.0   \n",
       "17620         Keysborough          19 Denmark Rd      5    h  1100000.0   \n",
       "18141               Lalor           83 Rotino Cr      3    t   463000.0   \n",
       "18614           Mickleham        17 Primavera Dr      4    h   610000.0   \n",
       "18793             Wollert      13 Strathalbyn Ch      4    h   631000.0   \n",
       "18995           Greenvale         40 Frontier Av      3    t   470000.0   \n",
       "\n",
       "      Method        SellerG        Date  Distance  Postcode  Bedroom2  \\\n",
       "2572      VB      Fletchers  17-09-2016      11.7    3125.0       3.0   \n",
       "3257       S  hockingstuart  27-06-2016       3.4    3068.0       1.0   \n",
       "4485       S            Jas  27-11-2016       6.4    3011.0       3.0   \n",
       "5170       S             RT  28-05-2016      14.5    3188.0       4.0   \n",
       "10745      S        Sweeney  27-11-2016       8.9    3016.0       1.0   \n",
       "13223     PI           Icon  29-04-2017       2.8    3000.0       3.0   \n",
       "14008      S  hockingstuart  20-05-2017      10.9    3012.0       3.0   \n",
       "14132     PI         Nelson  29-04-2017       2.3    3051.0       2.0   \n",
       "14139      S       Woodards  22-04-2017      14.7    3167.0       4.0   \n",
       "14142      S       Woodards  29-04-2017      14.7    3167.0       3.0   \n",
       "14143     PI         Buxton  29-04-2017      14.7    3167.0       5.0   \n",
       "14976      S           Brad  03-06-2017       7.5    3040.0       3.0   \n",
       "15278     SP        Sweeney  03-06-2017       5.1    3011.0       4.0   \n",
       "15561      S        McGrath  17-06-2017      23.0    3136.0       3.0   \n",
       "16358      S        Rendina  24-06-2017       3.4    3031.0       2.0   \n",
       "16564     PI      Considine  24-06-2017       8.2    3041.0       3.0   \n",
       "17616     PI        Rendina  08-07-2017       3.4    3031.0       1.0   \n",
       "17620     PI       VicHomes  08-07-2017      25.2    3173.0       5.0   \n",
       "18141      S            HAR  12-08-2017      16.3    3075.0       3.0   \n",
       "18614      S            Ray  15-07-2017      20.6    3064.0       4.0   \n",
       "18793     PI  hockingstuart  15-07-2017      25.5    3750.0       4.0   \n",
       "18995     SP          Barry  22-07-2017      20.4    3059.0       3.0   \n",
       "\n",
       "       Bathroom  Car  Landsize  Lattitude  Longtitude  \\\n",
       "2572        2.0  2.0     263.0        NaN         NaN   \n",
       "3257        1.0  1.0       0.0        NaN         NaN   \n",
       "4485        2.0  2.0      98.0        NaN         NaN   \n",
       "5170        3.0  1.0     300.0        NaN         NaN   \n",
       "10745       1.0  1.0      46.0        NaN         NaN   \n",
       "13223       3.0  2.0       0.0        NaN         NaN   \n",
       "14008       1.0  2.0     667.0        NaN         NaN   \n",
       "14132       1.0  1.0    1537.0        NaN         NaN   \n",
       "14139       2.0  2.0     553.0        NaN         NaN   \n",
       "14142       2.0  4.0     590.0        NaN         NaN   \n",
       "14143       2.0  2.0     532.0        NaN         NaN   \n",
       "14976       2.0  1.0     321.0        NaN         NaN   \n",
       "15278       3.0  2.0     169.0        NaN         NaN   \n",
       "15561       2.0  2.0     319.0        NaN         NaN   \n",
       "16358       2.0  2.0       0.0        NaN         NaN   \n",
       "16564       2.0  2.0     216.0        NaN         NaN   \n",
       "17616       1.0  1.0    1053.0        NaN         NaN   \n",
       "17620       3.0  2.0     522.0        NaN         NaN   \n",
       "18141       2.0  2.0     114.0        NaN         NaN   \n",
       "18614       2.0  2.0     490.0        NaN         NaN   \n",
       "18793       2.0  2.0     400.0        NaN         NaN   \n",
       "18995       2.0  2.0     201.0        NaN         NaN   \n",
       "\n",
       "                       Regionname  Propertycount  \n",
       "2572        Southern Metropolitan         5678.0  \n",
       "3257        Northern Metropolitan         2954.0  \n",
       "4485         Western Metropolitan         7570.0  \n",
       "5170        Southern Metropolitan         2356.0  \n",
       "10745        Western Metropolitan          802.0  \n",
       "13223       Northern Metropolitan        17496.0  \n",
       "14008        Western Metropolitan          962.0  \n",
       "14132       Northern Metropolitan         6821.0  \n",
       "14139  South-Eastern Metropolitan         3692.0  \n",
       "14142  South-Eastern Metropolitan         3692.0  \n",
       "14143  South-Eastern Metropolitan         3692.0  \n",
       "14976        Western Metropolitan         9264.0  \n",
       "15278        Western Metropolitan         2417.0  \n",
       "15561        Eastern Metropolitan        11925.0  \n",
       "16358       Northern Metropolitan         5263.0  \n",
       "16564        Western Metropolitan         3284.0  \n",
       "17616       Northern Metropolitan         5263.0  \n",
       "17620  South-Eastern Metropolitan         8459.0  \n",
       "18141       Northern Metropolitan         8279.0  \n",
       "18614       Northern Metropolitan         1158.0  \n",
       "18793       Northern Metropolitan         2940.0  \n",
       "18995       Northern Metropolitan         4864.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows having Lattitude and Longitude missing\n",
    "df[np.isnan(df['Lattitude'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the same rows have ```Lattitude``` and ```Longitude``` missing. Let's look at the summary stats of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13581.000000</td>\n",
       "      <td>13581.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-37.809204</td>\n",
       "      <td>144.995221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.079257</td>\n",
       "      <td>0.103913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-38.182550</td>\n",
       "      <td>144.431810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-37.856820</td>\n",
       "      <td>144.929600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-37.802360</td>\n",
       "      <td>145.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-37.756400</td>\n",
       "      <td>145.058320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-37.408530</td>\n",
       "      <td>145.526350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lattitude    Longtitude\n",
       "count  13581.000000  13581.000000\n",
       "mean     -37.809204    144.995221\n",
       "std        0.079257      0.103913\n",
       "min      -38.182550    144.431810\n",
       "25%      -37.856820    144.929600\n",
       "50%      -37.802360    145.000100\n",
       "75%      -37.756400    145.058320\n",
       "max      -37.408530    145.526350"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, ['Lattitude', 'Longtitude']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the distribution of both ```Lattitude``` and ```Longitude``` is quite narrow. \n",
    "\n",
    "A good way to estimate the 'spread of data' is to look at the difference between the mean and the median (lower the better), and the variation from 25th to 75th percentile (quite small in this case).\n",
    "\n",
    "Thus, let's impute the missing values by the mean value of ```Lattitude``` and ```Longitude``` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb           0.00\n",
       "Address          0.00\n",
       "Rooms            0.00\n",
       "Type             0.00\n",
       "Price            0.00\n",
       "Method           0.00\n",
       "SellerG          0.00\n",
       "Date             0.00\n",
       "Distance         0.00\n",
       "Postcode         0.00\n",
       "Bedroom2         0.00\n",
       "Bathroom         0.01\n",
       "Car              0.46\n",
       "Landsize         0.00\n",
       "Lattitude        0.00\n",
       "Longtitude       0.00\n",
       "Regionname       0.00\n",
       "Propertycount    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imputing Lattitude and Longitude by mean values\n",
    "df.loc[np.isnan(df['Lattitude']), ['Lattitude']] = df['Lattitude'].mean()\n",
    "df.loc[np.isnan(df['Longtitude']), ['Longtitude']] = df['Longtitude'].mean()\n",
    "\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have ```Bathroom``` and ```Car``` with 0.01% and 0.46% NaNs respectively. \n",
    "\n",
    "Since these are very small number of rows, it does not really matter whether you delete or impute. However, let's have a look at the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13602.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.534921</td>\n",
       "      <td>1.610414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.691834</td>\n",
       "      <td>0.962244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bathroom           Car\n",
       "count  13602.000000  13540.000000\n",
       "mean       1.534921      1.610414\n",
       "std        0.691834      0.962244\n",
       "min        0.000000      0.000000\n",
       "25%        1.000000      1.000000\n",
       "50%        1.000000      2.000000\n",
       "75%        2.000000      2.000000\n",
       "max        8.000000     10.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, ['Bathroom', 'Car']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two are integer type variables, and thus have values 0, 1, 2 etc. You cannot impute the NaNs by the mean or the median (1.53 bathrooms does not make sense!).\n",
    "\n",
    "Thus, you need to impute them by the mode - the most common occurring value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0     5606\n",
       "1.0     5515\n",
       "0.0     1026\n",
       "3.0      748\n",
       "4.0      507\n",
       "5.0       63\n",
       "6.0       54\n",
       "8.0        9\n",
       "7.0        8\n",
       "10.0       3\n",
       "9.0        1\n",
       "Name: Car, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to type 'category'\n",
    "df['Car'] = df['Car'].astype('category')\n",
    "\n",
    "# displaying frequencies of each category\n",
    "df['Car'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common value of ```Car``` is 2 (dtype is int), so let's impute the NaNs by that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb           0.00\n",
       "Address          0.00\n",
       "Rooms            0.00\n",
       "Type             0.00\n",
       "Price            0.00\n",
       "Method           0.00\n",
       "SellerG          0.00\n",
       "Date             0.00\n",
       "Distance         0.00\n",
       "Postcode         0.00\n",
       "Bedroom2         0.00\n",
       "Bathroom         0.01\n",
       "Car              0.00\n",
       "Landsize         0.00\n",
       "Lattitude        0.00\n",
       "Longtitude       0.00\n",
       "Regionname       0.00\n",
       "Propertycount    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imputing NaNs by 2.0\n",
    "df.loc[pd.isnull(df['Car']), ['Car']] = 2\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for ```Bathroom```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    7517\n",
       "2.0    4987\n",
       "3.0     921\n",
       "4.0     106\n",
       "0.0      34\n",
       "5.0      28\n",
       "6.0       5\n",
       "8.0       2\n",
       "7.0       2\n",
       "Name: Bathroom, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to type 'category'\n",
    "df['Bathroom'] = df['Bathroom'].astype('category')\n",
    "\n",
    "# displaying frequencies of each category\n",
    "df['Bathroom'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb           0.0\n",
       "Address          0.0\n",
       "Rooms            0.0\n",
       "Type             0.0\n",
       "Price            0.0\n",
       "Method           0.0\n",
       "SellerG          0.0\n",
       "Date             0.0\n",
       "Distance         0.0\n",
       "Postcode         0.0\n",
       "Bedroom2         0.0\n",
       "Bathroom         0.0\n",
       "Car              0.0\n",
       "Landsize         0.0\n",
       "Lattitude        0.0\n",
       "Longtitude       0.0\n",
       "Regionname       0.0\n",
       "Propertycount    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imputing NaNs by 1\n",
    "df.loc[pd.isnull(df['Bathroom']), ['Bathroom']] = 1\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataframe with no missing values. Let's finally look at how many rows (apart from three columns) we have lost in the process (originally we had 23547):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13603, 18)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5776956724848176"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fraction of rows lost\n",
    "len(df.index)/23547"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have lost about 42% observations in cleaning the missing values. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
